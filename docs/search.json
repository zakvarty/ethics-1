[{"path":"index.html","id":"welcome","chapter":"Welcome!","heading":"Welcome!","text":"Data-driven decision making now pervasive impacts us . data used others make decisions , behave, options made available . Predictive models used decide anything promotion offered retailer whether loan application granted bank.ways predictive models can fail mathematically form core part training aspiring statistician, data scientist machine learning practitioner. contrast, potential ethical failures models rarely covered -depth part initial training. result, ethical modes failure often considered predictive models put production actively causing harm.prevent harm, ethical impacts using data make decisions must made core curriculum statistics data science. course aims address gap.course takes practical technical approach identifying ethical issues. strong mathematical focus require authoring extended essays moral treaties. Throughout course, give actionable ways topics may integrated data science workflow range levels.","code":""},{"path":"index.html","id":"module-description","chapter":"Welcome!","heading":"Module Description","text":"module investigate ethical implications new capabilities offered Data Science Artificial Intelligence.Part 1 begin discussing ethical use data - raw materials data science pipelines. discuss sets principles tech leaders international bodies adopting promote ethical use data science artificial intelligence algorithms, including discussion real-world examples failings adverse outcomes.Parts 2 3 revisit issues explored Part 1 greater technical detail. parts introduce data science methodologies provide novel solutions ethical problems old explainability, prejudice bias.","code":""},{"path":"index.html","id":"learning-objectives","chapter":"Welcome!","heading":"Learning Objectives","text":"successful completion module, able :Recognise accept responsibility societal impact data science machine learning technologies;Participate broader debate issues surrounding use data science machine learning prediction, decision making knowledge generation tasks;Identify common ethical pitfalls data science ML algorithms via mental “check-list” evaluate degree given algorithm likely conform ethical best practices.Formally test common ethical pitfalls data science ML algorithms.Implement mitigation measures ethical risks posed use data science ML algorithms.Construct well-founded evidence-based arguments positively influence actions stakeholders decision-makers;Use systems perspective holistically appraise data science projects ethical societal impacts.","code":""},{"path":"index.html","id":"contributors","chapter":"Welcome!","heading":"Contributors","text":"notes structured around course delivered part Master’s degree Machine Learning Data Science Imperial College London, developed Christoforos Anagnostopoulos Zak Varty.course notes written Zak Varty still active development. spot issues like contribute development, may raise issue submit pull request associated github repository.","code":""},{"path":"course-overview.html","id":"course-overview","chapter":"Course Overview","heading":"Course Overview","text":"section relevant students taking MLDS course academic year 2022-23.","code":""},{"path":"course-overview.html","id":"assessments","chapter":"Course Overview","heading":"0.1 Assessments","text":"Assessment schedule Ethics Part 1 (2022 Cohort)","code":""},{"path":"ch-foundations.html","id":"ch-foundations","chapter":"1 Foundations of Ethical AI","heading":"1 Foundations of Ethical AI","text":"","code":""},{"path":"ch-foundations.html","id":"introduction","chapter":"1 Foundations of Ethical AI","heading":"Introduction","text":"Welcome first week unique course.likely different course taken come scientific engineering background. often spend days without seeing equation, asked think carefully real-world implications work.said , rest assured plenty technical mathematical content course, content purely conceptual immediately relevant life professional data scientist.course moral philosophy, really hope encourage take one. , let’s get started.week, ’ll spend time getting understand precisely mean harm, mean data science , moral frameworks codes conduct already place, finally codify set five principles can use guardrails work professional data scientists.Although term AI course title, sometimes collectively refer subject ethical AI. ’s necessarily accurate. tendency days label even simple data analysis AI can misleading. Also, flavours AI use data learning. However, literature regulation around topic professional ethics increasingly consolidating term ethical AI, use short cut.can safely assume whenever use term AI, referring statistical machine learning data science, focus program ’re attending.right. Disclaimers aside, week cover huge amount conceptual ground.also week entire course mathematical programming content, sit back enjoy.","code":""},{"path":"ch-foundations.html","id":"do-no-harm","chapter":"1 Foundations of Ethical AI","heading":"1.1 Do No Harm","text":"","code":""},{"path":"ch-foundations.html","id":"ai-for-good","chapter":"1 Foundations of Ethical AI","heading":"1.1.1 AI for good","text":"","code":""},{"path":"ch-foundations.html","id":"go","chapter":"1 Foundations of Ethical AI","heading":"1.1.1.1 Go","text":"hard open news website days come across headline celebrates incredible achievements AI algorithms. Millions people held breath DeepMind’s neural network AlphaGo played game Go, world’s challenging strategy board game, world champion, Eventually landing victory ushering era AI supremacy yet another frontier human intelligence.makes moment dramatic computer becomes world champion certain game, say chess go, means basic algorithmic design, allowing learn play game finally place.given year--year increases computational power, computer can get better better much faster pace human can. Put differently,\nhuman never manage compete state---art AI chess go.common criticism AI used can outperform humans toy\ndomains games , though fascinating, really help humanity. also used criticise AI systems narrow, example, able deal one task time. Now, era seems .","code":""},{"path":"ch-foundations.html","id":"protein-folding","chapter":"1 Foundations of Ethical AI","heading":"1.1.1.2 Protein folding","text":"DeepMind recently demonstrated algorithm architecturally similar AlphaGo able solve riddle biochemistry holds promise \nrevolutionising drug discovery. known protein folding, \ntask predicting 3D shape protein basis sequence amino acids made .Proteins complex twisty things way fold depends number spontaneous interactions different parts amino acids. hard computational\nproblem solve exactly.AI researchers instead opted predictive modeling using large database known structures training data set predicting likely shape new proteins .","code":""},{"path":"ch-foundations.html","id":"arrhythmia","chapter":"1 Foundations of Ethical AI","heading":"1.1.1.3 Arrhythmia","text":"AI now reaching superhuman performance games scientific problems lab, also everyday real-world tasks currently require\nwell-trained professional.example, cardiologists can detect arrhythmia inspecting echocardiogram patient. ’s graph electrical\nactivity heart.Recent work Andrew Ng others demonstrated AI algorithm able perform task similar performance can milliseconds everywhere world, just reliably.implications remote health care care patients countries without robust health care systems absence specialist doctors mind-blowing. yet, increasingly also hear news stories AI getting wrong.","code":""},{"path":"ch-foundations.html","id":"ai-can-cause-harm","chapter":"1 Foundations of Ethical AI","heading":"1.1.2 AI can cause harm","text":"","code":""},{"path":"ch-foundations.html","id":"self-driving","chapter":"1 Foundations of Ethical AI","heading":"1.1.2.1 Self-driving","text":"Self-driving cars particularly interesting example ethical AI.driving relatively easy task humans; learn matter months us can reasonably well. Yet, Artificial Intelligence system, driving much harder chess.requires advanced computer vision, planning movement forecasting.\nthings humans animals excel evolved\nmillions years move avoiding objects various conditions,\nincluding rain, low visibility range different physical environments.Similarly, driving safely requires knowing dog unpredictable ,\nsay, pedestrian elderly man typically walks slower teenager. didn’t learn facts driving lessons. know drive\ncar, need understand much just cars, roads, roadsides.Despite huge challenges, self-driving cars remain incredibly valuable business proposition. Therefore, many tech companies car manufacturers competing space.Inevitably, self-driving car occasionally enter accident \nfatal. statement relative\nsafety self-driving AI versus human driving. Current statistics suggest \nexisting self-driving cars much safer humans scale number accidents per mile drive, trend likely persist.yet, fatal accident happen, blame? avoided?data scientist worked algorithm blame?model’s fault data’s fault? , blame?hard important questions never ask . also subtler equally important ways AI can cause harm.AI increasingly used daily lives, make mistakes without care, mistakes may disproportionately affect minorities, vulnerable populations groups subject\nhistoric discrimination.","code":""},{"path":"ch-foundations.html","id":"facial-recognition","chapter":"1 Foundations of Ethical AI","heading":"1.1.2.2 Facial recognition","text":"Facial recognition one particular example combination poor quality data poor governance led headline grabbing failures.news articles (academic articles based) draw attention fact algorithms reliably perform worse faces people colour.mistakes can hurtful perpetuate historic racism. can also lead real-world discrimination cases algorithms used, example police., crossroad sorts. decades broken promises,\nAI starting powerful enough solve real-world problems even outperform humans number valuable tasks. However, adoption technologies increases risk harm.Whereas , AI researchers playing harmlessly toy examples\nuniversity labs, now increasingly holding lives livelihoods hands.first time happens. fact, happens nearly\nevery powerful emerging technology.","code":""},{"path":"ch-foundations.html","id":"technological-adoption-requires-public-trust","chapter":"1 Foundations of Ethical AI","heading":"1.1.3 Technological Adoption Requires Public Trust","text":"","code":""},{"path":"ch-foundations.html","id":"nuclear-power","chapter":"1 Foundations of Ethical AI","heading":"1.1.3.1 Nuclear Power","text":"One particular example ’ll come back nuclear power.nuclear bomb, theoretical physicists completely\nprotected academic ivory towers, unwilling unable affect\nmess real world.Suddenly, right set equations wartime effort make use \nchanged . Iconic names like Richard Feynman Albert Einstein suddenly got thrown one heated moral debates century.Even putting aside question nuclear weapons, nuclear power struggled secure public trust even used peaceful purposes like energy production. time climate energy crisis, nuclear power one truly sustainable sources energy , comes considerable safety problem.Although, nuclear disasters , occur, can \ndevastating particularly terrifying, happen\nstruggling economies failures might attributed poor practices.\ncan even happen technologically advanced economies like Japan.Trust hard earn easy lose, headline makes\nwidespread adoption nuclear power exponentially harder. similar future might await AI unless act now., whose responsibility ensure AI fares better ? Well, expect physicists engineers carry burden responsibility explaining exactly safe nuclear reactor , needs maintained remain safe, ’re \nones understand well enough.","code":""},{"path":"ch-foundations.html","id":"taking-responsibility","chapter":"1 Foundations of Ethical AI","heading":"1.1.3.2 Taking responsibility","text":"Similarly, data scientists like first line defence \nharmful AI ones understand systems well enough anticipate might go wrong .Just like theoretical physicists early 20th century, data scientists onset big data worry work limited impact specific conditions.Now data science AI increasingly becoming part fabric\nsociety economy, carry burden demonstrate safety.\ndata scientists, alone ; many professions carry similar\nburden responsibility abide strict codes conduct legally liable outcomes work.","code":""},{"path":"ch-foundations.html","id":"learning-from-other-professions","chapter":"1 Foundations of Ethical AI","heading":"1.1.4 Learning from other professions","text":"Doctors drug design researchers one example, prominent pandemic era. also ,quotidian, examples rarely think including lawyers engineers build infrastructure\nuse daily basis like houses live , power network, transport network, bridges hope don’t fall.professions know lives depend getting things right hence adopt safety-first approach risk-management. inviting adopt work.Doctors particularly interesting example , antiquity, explicit moral obligations.","code":""},{"path":"ch-foundations.html","id":"hippocratic-oath","chapter":"1 Foundations of Ethical AI","heading":"1.1.4.1 Hippocratic Oath","text":"early 2,500 years ago, doctors swear Hippocratic oath,\namong things included commitment medical confidentiality non-maleficence, commonly known, “harm”.idea doctor take unnecessary risks considering\ntreatment options patient. simple command tremendous\ninfluence throughout centuries understanding professional ethics.\nmay even lie core recent corporate mission statements, famous motto, “don’t evil”, google used opening statement internal code conduct. later rephrased “\ncan make money without evil”, cases captures aspiration\ncompanies strive hurt society users \nproducts, even try make profit.dual allegiance theme return course core objective professional codes conduct. seeking something like Hippocratic oath data scientists.","code":""},{"path":"ch-foundations.html","id":"hippocratic-oath-for-data-scientists","chapter":"1 Foundations of Ethical AI","heading":"1.1.4.2 Hippocratic Oath for Data Scientists","text":"Doctors start thinking medical ethics early training literally stand front crowd taking oath hurt patients \nprotect privacy, amongst things.profession broad impact data science similar process, Cathy O’Neil argued 2016 book Weapons Math Destruction.haven’t yet quite decided whether take oath together \ncourse completed, definitely idea.’ve invited think using AI good ensuring safe.\neasy , really?","code":""},{"path":"ch-foundations.html","id":"doing-the-right-thing-is-neither-obvious-nor-is-it-easy","chapter":"1 Foundations of Ethical AI","heading":"1.1.5 Doing the right thing is neither obvious nor is it easy","text":"turns right thing neither obvious easy.often lack context lack understanding group risk. Unless advocates representing group consulted, ignorance might dangerous.Moreover, even necessary facts, humans often hampered cognitive biases bad habits. Processes need place \novercome sources error. Even cases know\nright thing , might difficult unless right incentive structures place.safe raise certain concern company likely negatively impact career progression, fewer people courage determination .build organisations don’t hero \nright thing. certain situations, even knowledge \nright thing present, faced moral dilemmas one harm must balanced another. Given , easy give . Just problem big fix immediately, mean can’t make progress.Finally, despite best efforts, technology can sometimes unanticipated consequences. humble attitude learn mistakes needed least ensure accident happens twice.said , clarify won’t attempt define\nright course. ’s hard, course moral philosophy. , instructors mathematicians, social scientists philosophers. mostly take certain values given, see later week.can maybe think course attempt change default perspective work. might used focusing success stories likely positive impact work, now start think near-misses: things gone wrong anticipate harm might caused.might focus access data, now start think whether permission use data certain way., might committed good evil, making emotionally difficult admit work necessarily entail risk harm. Now, might start humbly accept risk commit best can mitigate ., might even thought part job data scientist worry things. Going forward, specialist field, see responsibility raise bar.see unsolvable moral dilemmas, now seek explicitly\nquantify trade-offs informed conversation right balance.might hoped eventually technology solve problems, just focus research; now, approach problem pragmatically, acknowledging problems can solved technology case afford wait.Whereas ’d obsessed model’s performance, now start monitor things care , degree protects privacy treats people fairly.finally, might preferred discuss things fellow engineers scientists, now feel confident engage\nconversation broader society.","code":""},{"path":"ch-foundations.html","id":"conclusion","chapter":"1 Foundations of Ethical AI","heading":"1.1.6 Conclusion","text":"sum , established power comes responsibility , trained professional, best placed driver positive change.argued core safe benevolent AI ability anticipate\nharm, minimise (even can’t eliminate altogether) communicate transparently public.also showed important think humans impacted technology, putting human centre design \njust talking technology .follows, pause better define data scientists actually build, can specific tying potential harm different components data science pipeline.discuss progress made date way codifying ethics data science AI, conclude week offering codification problem area five major principles.five principles also serve backbone rest course.Thank welcome aboard.","code":""},{"path":"ch-privacy-and-autonomy.html","id":"ch-privacy-and-autonomy","chapter":"2 Privacy and Autonomy","heading":"2 Privacy and Autonomy","text":"Cross-references make easier readers find link elements book.","code":""},{"path":"ch-privacy-and-autonomy.html","id":"captioned-figures-and-tables","chapter":"2 Privacy and Autonomy","heading":"2.1 Captioned figures and tables","text":"Figures tables captions can also cross-referenced elsewhere book using \\@ref(fig:chunk-label) \\@ref(tab:chunk-label), respectively.See Figure 2.1.\nFigure 2.1: nice figure!\nDon’t miss Table 2.1.Table 2.1: nice table!","code":"\npar(mar = c(4, 4, .1, .1))\nplot(pressure, type = 'b', pch = 19)\nknitr::kable(\n  head(pressure, 10), caption = 'Here is a nice table!',\n  booktabs = TRUE\n)"},{"path":"ch-fairness.html","id":"ch-fairness","chapter":"3 Fairness","heading":"3 Fairness","text":"can add parts organize one book chapters together. Parts can inserted top .Rmd file, first-level chapter heading file.Add numbered part: # (PART) Act one {-} (followed # chapter)Add unnumbered part: # (PART\\*) Act one {-} (followed # chapter)Add appendix special kind un-numbered part: # (APPENDIX) stuff {-} (followed # chapter). Chapters appendix prepended letters instead numbers.","code":""},{"path":"ch-alignment-and-control.html","id":"ch-alignment-and-control","chapter":"4 Alignment and Control","heading":"4 Alignment and Control","text":"","code":""},{"path":"ch-alignment-and-control.html","id":"footnotes","chapter":"4 Alignment and Control","heading":"4.1 Footnotes","text":"Footnotes put inside square brackets caret ^[]. Like one 1.","code":""},{"path":"ch-alignment-and-control.html","id":"citations","chapter":"4 Alignment and Control","heading":"4.2 Citations","text":"Reference items bibliography file(s) using @key.example, using bookdown package2 (check last code chunk index.Rmd see citation key added) sample book, built top R Markdown knitr3 (citation added manually external file book.bib).\nNote .bib files need listed index.Rmd YAML bibliography key.bs4_book theme makes footnotes appear inline click . example book, added csl: chicago-fullnote-bibliography.csl index.Rmd YAML, include .csl file. download new style, recommend: https://www.zotero.org/styles/RStudio Visual Markdown Editor can also make easier insert citations: https://rstudio.github.io/visual-markdown-editing/#/citations","code":""},{"path":"ch-explainability.html","id":"ch-explainability","chapter":"5 Explainability and Interpretability","heading":"5 Explainability and Interpretability","text":"","code":""},{"path":"ch-explainability.html","id":"equations","chapter":"5 Explainability and Interpretability","heading":"5.1 Equations","text":"equation.\\[\\begin{equation}\n  f\\left(k\\right) = \\binom{n}{k} p^k\\left(1-p\\right)^{n-k}\n  \\tag{5.1}\n\\end{equation}\\]may refer using \\@ref(eq:binom), like see Equation (5.1).","code":""},{"path":"ch-explainability.html","id":"theorems-and-proofs","chapter":"5 Explainability and Interpretability","heading":"5.2 Theorems and proofs","text":"Theorem 5.1  right triangle, \\(c\\) denotes length hypotenuse\n\\(\\) \\(b\\) denote lengths two sides, \n\\[^2 + b^2 = c^2\\]Labeled theorems can referenced text using \\@ref(thm:tri), example, check smart theorem 5.1.Read https://bookdown.org/yihui/bookdown/markdown-extensions--bookdown.html.","code":""},{"path":"ch-explainability.html","id":"callout-blocks","chapter":"5 Explainability and Interpretability","heading":"5.3 Callout blocks","text":"bs4_book theme also includes special callout blocks, like .rmdnote.can use markdown inside block.user define appearance blocks LaTeX output.may also use: .rmdcaution, .rmdimportant, .rmdtip, .rmdwarning block name.R Markdown Cookbook provides help use custom blocks design callouts: https://bookdown.org/yihui/rmarkdown-cookbook/custom-blocks.html","code":"\nhead(beaver1, n = 5)\n#>   day time  temp activ\n#> 1 346  840 36.33     0\n#> 2 346  850 36.34     0\n#> 3 346  900 36.35     0\n#> 4 346  910 36.42     0\n#> 5 346  920 36.55     0"},{"path":"ch-safety.html","id":"ch-safety","chapter":"6 Safety, Security and Accountability","heading":"6 Safety, Security and Accountability","text":"","code":""},{"path":"ch-safety.html","id":"publishing","chapter":"6 Safety, Security and Accountability","heading":"6.1 Publishing","text":"HTML books can published online, see: https://bookdown.org/yihui/bookdown/publishing.html","code":""},{"path":"ch-safety.html","id":"pages","chapter":"6 Safety, Security and Accountability","heading":"6.2 404 pages","text":"default, users directed 404 page try access webpage found. ’d like customize 404 page instead using default, may add either _404.Rmd _404.md file project root use code /Markdown syntax.","code":""},{"path":"ch-safety.html","id":"metadata-for-sharing","chapter":"6 Safety, Security and Accountability","heading":"6.3 Metadata for sharing","text":"Bookdown HTML books provide HTML metadata social sharing platforms like Twitter, Facebook, LinkedIn, using information provide index.Rmd YAML. setup, set url book path cover-image file. book’s title description also used.bs4_book provides enhanced metadata social sharing, chapter shared unique description, auto-generated based content.Specify book’s source repository GitHub repo _output.yml file, allows users view chapter’s source file suggest edit. Read features output format :https://pkgs.rstudio.com/bookdown/reference/bs4_book.htmlOr use:","code":"\n?bookdown::bs4_book"},{"path":"license.html","id":"license","chapter":"License","heading":"License","text":"work licensed Creative Commons Attribution-ShareAlike 4.0 International License.human-readable summary (substitute ) license.\nPlease see https://creativecommons.org/licenses/-sa/4.0/legalcode full legal text.free :Share—copy redistribute material medium \nformatShare—copy redistribute material medium \nformatRemix—remix, transform, build upon material \npurpose, even commercially.Remix—remix, transform, build upon material \npurpose, even commercially.licensor revoke freedoms long follow \nlicense terms.following terms:Attribution—must give appropriate credit, provide link\nlicense, indicate changes made. may \nreasonable manner, way suggests licensor\nendorses use.Attribution—must give appropriate credit, provide link\nlicense, indicate changes made. may \nreasonable manner, way suggests licensor\nendorses use.ShareAlike—remix, transform, build upon material, must distribute contributions license original.ShareAlike—remix, transform, build upon material, must distribute contributions license original.additional restrictions—may apply legal terms \ntechnological measures legally restrict others \nanything license permits.additional restrictions—may apply legal terms \ntechnological measures legally restrict others \nanything license permits.Notices:comply license elements \nmaterial public domain use permitted \napplicable exception limitation.warranties given. license may give \npermissions necessary intended use. example, rights\npublicity, privacy, moral rights may limit use \nmaterial.","code":""},{"path":"build-information.html","id":"build-information","chapter":"Build Information","heading":"Build Information","text":"book written bookdown inside RStudio. website ethics-1.zakvarty.com hosted Netlify. complete source available GitHub.course logo designed Zak Varty.version book built :Along packages:","code":"#>  setting  value\n#>  version  R version 4.2.0 (2022-04-22)\n#>  os       macOS Big Sur/Monterey 10.16\n#>  system   x86_64, darwin17.0\n#>  ui       X11\n#>  language (EN)\n#>  collate  en_GB.UTF-8\n#>  ctype    en_GB.UTF-8\n#>  tz       Europe/London\n#>  date     2022-07-28\n#>  pandoc   2.18 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)"},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
