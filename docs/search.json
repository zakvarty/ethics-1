[{"path":"index.html","id":"welcome","chapter":"Welcome!","heading":"Welcome!","text":"Data-driven decision making now pervasive impacts us . data used others make decisions , behave, options made available . Predictive models used decide anything promotion offered retailer whether loan application granted bank.ways predictive models can fail mathematically form core part training aspiring statistician, data scientist machine learning practitioner. contrast, potential ethical failures models rarely covered -depth part initial training. result, ethical modes failure often considered predictive models put production actively causing harm.prevent harm, ethical impacts using data make decisions must made core curriculum statistics data science. course aims address gap.course takes practical technical approach identifying ethical issues. strong mathematical focus require authoring extended essays moral treaties. Throughout course, give actionable ways topics may integrated data science workflow range levels.","code":""},{"path":"index.html","id":"module-description","chapter":"Welcome!","heading":"Module Description","text":"module investigate ethical implications new capabilities offered Data Science Artificial Intelligence.Part 1 begin discussing ethical use data - raw materials data science pipelines. discuss sets principles tech leaders international bodies adopting promote ethical use data science artificial intelligence algorithms, including discussion real-world examples failings adverse outcomes.Parts 2 3 revisit issues explored Part 1 greater technical detail. parts introduce data science methodologies provide novel solutions ethical problems old explainability, prejudice bias.","code":""},{"path":"index.html","id":"learning-objectives","chapter":"Welcome!","heading":"Learning Objectives","text":"successful completion module, able :Recognise accept responsibility societal impact data science machine learning technologies;Participate broader debate issues surrounding use data science machine learning prediction, decision making knowledge generation tasks;Identify common ethical pitfalls data science ML algorithms via mental “check-list” evaluate degree given algorithm likely conform ethical best practices;Formally test common ethical pitfalls data science ML algorithms;Implement mitigation measures ethical risks posed use data science ML algorithms;Construct well-founded evidence-based arguments positively influence actions stakeholders decision-makers;Use systems perspective holistically appraise data science projects ethical societal impacts.","code":""},{"path":"index.html","id":"contributors","chapter":"Welcome!","heading":"Contributors","text":"notes structured around course delivered part Master’s degree Machine Learning Data Science Imperial College London, developed Christoforos Anagnostopoulos Zak Varty.course notes written Zak Varty still active development. spot issues like contribute development, may raise issue submit pull request associated github repository.","code":""},{"path":"course-overview.html","id":"course-overview","chapter":"Course Overview","heading":"Course Overview","text":"section relevant students taking MLDS course \nacademic year 2022-23.","code":""},{"path":"course-overview.html","id":"assessments","chapter":"Course Overview","heading":"0.1 Assessments","text":"Assessment schedule Ethics Part 1 (2022 Cohort)","code":""},{"path":"course-overview.html","id":"reading-summaries","chapter":"Course Overview","heading":"0.2 Reading summaries","text":"wide range areas use AI lead harm\nindividual section society. lectures heard \nexample individual harm, advertisement maternity\nproducts woman miscarried. also heard example \ngroup harm, pre-trial assessments incorrectly predicted\nBlack defendants high risk individuals. assessed\nquestion consider another example use AI \ncaused harm.rhetorical precis short summary analysis piece \nwriting, considers content delivery piece.\nrhetorical precis includes accurate bibliographic reference \ntext, list keywords relating text, highly structured\nfour-sentence paragraph serves summarise analyse text.\nsentence specific role:first sentence establishes aim thesis work;second sentence explains aim addressed outlines\nsupporting arguments;third sentence states purpose work (\nimportant);final sentence describes intended audience tone \nwriting.example rhetorical precis can found lumenlearning\nwebsite.\nCreating summaries paper promotes clarity precision \nreading writing. also provides useful aid trying \nrecall contents paper long originally read .Select read academic article course reading\nlist either}highlights one harmful instance AI summarises\npotential harms AI generally. Write rhetorical precis \nselected paper, submit assessment. (Note: using text\ncourse materials reading list result 50% reduction\nmarks awarded question.)Accurate bibliographic reference keywords [1]Accurate bibliographic reference keywords [1]Aim thesis sentence [2]Aim thesis sentence [2]aim addressed / thesis argued [2]aim addressed / thesis argued [2]Purpose importance work [2]Purpose importance work [2]Identified target audience [2]Identified target audience [2]Selection paper included course reading list [1].Selection paper included course reading list [1].","code":""},{"path":"ch-foundations.html","id":"ch-foundations","chapter":"1 Foundations of Ethical AI","heading":"1 Foundations of Ethical AI","text":"","code":""},{"path":"ch-foundations.html","id":"introduction","chapter":"1 Foundations of Ethical AI","heading":"Introduction","text":"Welcome first week unique course.likely different course taken come scientific engineering background. often spend days without seeing equation, asked think carefully real-world implications work.said , rest assured plenty technical mathematical content course, content purely conceptual immediately relevant life professional data scientist.course moral philosophy, really hope encourage take one. , let’s get started.week, ’ll spend time getting understand precisely mean harm, mean data science , moral frameworks codes conduct already place, finally codify set five principles can use guardrails work professional data scientists.Although term AI course title, sometimes collectively refer subject ethical AI. ’s necessarily accurate. tendency days label even simple data analysis AI can misleading. Also, flavours AI use data learning. However, literature regulation around topic professional ethics increasingly consolidating term ethical AI, use short cut.can safely assume whenever use term AI, referring statistical machine learning data science, focus program ’re attending.right. Disclaimers aside, week cover huge amount conceptual ground.also week entire course mathematical programming content, sit back enjoy.","code":""},{"path":"ch-foundations.html","id":"do-no-harm","chapter":"1 Foundations of Ethical AI","heading":"1.1 Do No Harm","text":"","code":""},{"path":"ch-foundations.html","id":"ai-for-good","chapter":"1 Foundations of Ethical AI","heading":"1.1.1 AI for good","text":"","code":""},{"path":"ch-foundations.html","id":"go","chapter":"1 Foundations of Ethical AI","heading":"1.1.1.1 Go","text":"hard open news website days come across headline celebrates incredible achievements AI algorithms. Millions people held breath DeepMind’s neural network AlphaGo played game Go, world’s challenging strategy board game, world champion, Eventually landing victory ushering era AI supremacy yet another frontier human intelligence.makes moment dramatic computer becomes world champion certain game, say chess go, means basic algorithmic design, allowing learn play game finally place.given year--year increases computational power, computer can get better better much faster pace human can. Put differently,\nhuman never manage compete state---art AI chess go.common criticism AI used can outperform humans toy\ndomains games , though fascinating, really help humanity. also used criticise AI systems narrow, example, able deal one task time. Now, era seems .","code":""},{"path":"ch-foundations.html","id":"protein-folding","chapter":"1 Foundations of Ethical AI","heading":"1.1.1.2 Protein folding","text":"DeepMind recently demonstrated algorithm architecturally similar AlphaGo able solve riddle biochemistry holds promise \nrevolutionising drug discovery. known protein folding, \ntask predicting 3D shape protein basis sequence amino acids made .Proteins complex twisty things way fold depends number spontaneous interactions different parts amino acids. hard computational\nproblem solve exactly.AI researchers instead opted predictive modeling using large database known structures training data set predicting likely shape new proteins .","code":""},{"path":"ch-foundations.html","id":"arrhythmia","chapter":"1 Foundations of Ethical AI","heading":"1.1.1.3 Arrhythmia","text":"AI now reaching superhuman performance games scientific problems lab, also everyday real-world tasks currently require\nwell-trained professional.example, cardiologists can detect arrhythmia inspecting echocardiogram patient. ’s graph electrical\nactivity heart.Recent work Andrew Ng others demonstrated AI algorithm able perform task similar performance can milliseconds everywhere world, just reliably.implications remote health care care patients countries without robust health care systems absence specialist doctors mind-blowing. yet, increasingly also hear news stories AI getting wrong.","code":""},{"path":"ch-foundations.html","id":"ai-can-cause-harm","chapter":"1 Foundations of Ethical AI","heading":"1.1.2 AI can cause harm","text":"","code":""},{"path":"ch-foundations.html","id":"self-driving","chapter":"1 Foundations of Ethical AI","heading":"1.1.2.1 Self-driving","text":"Self-driving cars particularly interesting example ethical AI.driving relatively easy task humans; learn matter months us can reasonably well. Yet, Artificial Intelligence system, driving much harder chess.requires advanced computer vision, planning movement forecasting.\nthings humans animals excel evolved\nmillions years move avoiding objects various conditions,\nincluding rain, low visibility range different physical environments.Similarly, driving safely requires knowing dog unpredictable ,\nsay, pedestrian elderly man typically walks slower teenager. didn’t learn facts driving lessons. know drive\ncar, need understand much just cars, roads, roadsides.Despite huge challenges, self-driving cars remain incredibly valuable business proposition. Therefore, many tech companies car manufacturers competing space.Inevitably, self-driving car occasionally enter accident \nfatal. statement relative\nsafety self-driving AI versus human driving. Current statistics suggest \nexisting self-driving cars much safer humans scale number accidents per mile drive, trend likely persist.yet, fatal accident happen, blame? avoided?data scientist worked algorithm blame?model’s fault data’s fault? , blame?hard important questions never ask . also subtler equally important ways AI can cause harm.AI increasingly used daily lives, make mistakes without care, mistakes may disproportionately affect minorities, vulnerable populations groups subject\nhistoric discrimination.","code":""},{"path":"ch-foundations.html","id":"facial-recognition","chapter":"1 Foundations of Ethical AI","heading":"1.1.2.2 Facial recognition","text":"Facial recognition one particular example combination poor quality data poor governance led headline grabbing failures.news articles (academic articles based) draw attention fact algorithms reliably perform worse faces people colour.mistakes can hurtful perpetuate historic racism. can also lead real-world discrimination cases algorithms used, example police., crossroad sorts. decades broken promises,\nAI starting powerful enough solve real-world problems even outperform humans number valuable tasks. However, adoption technologies increases risk harm.Whereas , AI researchers playing harmlessly toy examples\nuniversity labs, now increasingly holding lives livelihoods hands.first time happens. fact, happens nearly\nevery powerful emerging technology.","code":""},{"path":"ch-foundations.html","id":"technological-adoption-requires-public-trust","chapter":"1 Foundations of Ethical AI","heading":"1.1.3 Technological Adoption Requires Public Trust","text":"","code":""},{"path":"ch-foundations.html","id":"nuclear-power","chapter":"1 Foundations of Ethical AI","heading":"1.1.3.1 Nuclear Power","text":"One particular example ’ll come back nuclear power.nuclear bomb, theoretical physicists completely\nprotected academic ivory towers, unwilling unable affect\nmess real world.Suddenly, right set equations wartime effort make use \nchanged . Iconic names like Richard Feynman Albert Einstein suddenly got thrown one heated moral debates century.Even putting aside question nuclear weapons, nuclear power struggled secure public trust even used peaceful purposes like energy production. time climate energy crisis, nuclear power one truly sustainable sources energy , comes considerable safety problem.Although, nuclear disasters , occur, can \ndevastating particularly terrifying, happen\nstruggling economies failures might attributed poor practices.\ncan even happen technologically advanced economies like Japan.Trust hard earn easy lose, headline makes\nwidespread adoption nuclear power exponentially harder. similar future might await AI unless act now., whose responsibility ensure AI fares better ? Well, expect physicists engineers carry burden responsibility explaining exactly safe nuclear reactor , needs maintained remain safe, ’re \nones understand well enough.","code":""},{"path":"ch-foundations.html","id":"taking-responsibility","chapter":"1 Foundations of Ethical AI","heading":"1.1.3.2 Taking responsibility","text":"Similarly, data scientists like first line defence harmful AI ones understand systems well enough anticipate might go wrong .Just like theoretical physicists early 20th century, data scientists onset big data worry work limited impact specific conditions.Now data science AI increasingly becoming part fabric society economy, carry burden demonstrate safety.data scientists, alone ; many professions carry similar burden responsibility abide strict codes conduct legally liable outcomes work.","code":""},{"path":"ch-foundations.html","id":"learning-from-other-professions","chapter":"1 Foundations of Ethical AI","heading":"1.1.4 Learning from other professions","text":"Doctors drug design researchers one example, prominent pandemic era. also ,quotidian, examples rarely think including lawyers engineers build infrastructure use daily basis like houses live , power network, transport network, bridges hope don’t fall.professions know lives depend getting things right hence adopt safety-first approach risk-management. inviting adopt work.Doctors particularly interesting example , antiquity, explicit moral obligations.","code":""},{"path":"ch-foundations.html","id":"hippocratic-oath","chapter":"1 Foundations of Ethical AI","heading":"1.1.4.1 Hippocratic Oath","text":"early 2,500 years ago, doctors swear Hippocratic oath, among things included commitment medical confidentiality non-maleficence, commonly known, “harm”.idea doctor take unnecessary risks considering treatment options patient. simple command tremendous influence throughout centuries understanding professional ethics. may even lie core recent corporate mission statements, famous motto, “don’t evil”, Google used opening statement internal code conduct. later rephrased “\ncan make money without evil”, cases captures aspiration companies strive hurt society users products, even try make profit.dual allegiance theme return course core objective professional codes conduct. seeking something like Hippocratic oath data scientists.","code":""},{"path":"ch-foundations.html","id":"hippocratic-oath-for-data-scientists","chapter":"1 Foundations of Ethical AI","heading":"1.1.4.2 Hippocratic Oath for Data Scientists","text":"Doctors start thinking medical ethics early training literally stand front crowd taking oath hurt patients protect privacy, amongst things.profession broad impact data science similar process, Cathy O’Neil argued 2016 book Weapons Math Destruction.haven’t yet quite decided whether take oath together course completed, definitely idea.’ve invited think using AI good ensuring safe. easy , really?","code":""},{"path":"ch-foundations.html","id":"doing-the-right-thing-is-neither-obvious-nor-is-it-easy","chapter":"1 Foundations of Ethical AI","heading":"1.1.5 Doing the right thing is neither obvious nor is it easy","text":"turns right thing neither obvious easy.often lack context lack understanding group risk. Unless advocates representing group consulted, ignorance might dangerous.Moreover, even necessary facts, humans often hampered cognitive biases bad habits. Processes need place overcome sources error.Even cases know right thing , might difficult unless right incentive structures place. safe raise certain concern company likely negatively impact career progression, fewer people courage determination .build organisations don’t hero right thing. certain situations, even knowledge right thing present, faced moral dilemmas one harm must balanced another. Given , easy give just problem big fix immediately, mean can’t make progress.Finally, despite best efforts, technology can sometimes unanticipated consequences. humble attitude learn mistakes needed least ensure accident happens twice.said , clarify won’t attempt define right course. ’s hard, course moral philosophy. , instructors mathematicians, social scientists philosophers. mostly take certain values given, see later week.can perhaps think course attempt change default perspective work. might used focusing success stories likely positive impact work, now start think near-misses: things gone wrong anticipate harm might caused.might focus access data, now start think whether permission use data certain way., might committed good evil, making emotionally difficult admit work necessarily entail risk harm. Now, might start humbly accept risk commit best can mitigate ., might even thought part job data scientist worry things. Going forward, specialist field, see responsibility raise bar.previously see unsolvable moral dilemmas, now seek explicitly quantify trade-offs informed conversation right balance.might hoped eventually technology solve problems, just focus research; now, approach problem pragmatically, acknowledging problems can solved technology case afford wait.Whereas ’d obsessed model’s performance, now start monitor things care , degree protects privacy treats people fairly.finally, might preferred discuss things fellow engineers scientists, now feel confident engage\nconversation broader society.","code":""},{"path":"ch-foundations.html","id":"conclusion","chapter":"1 Foundations of Ethical AI","heading":"1.1.6 Conclusion","text":"sum , established power comes responsibility , trained professional, best placed driver positive change.argued core safe benevolent AI ability anticipate\nharm, minimise (even can’t eliminate altogether) communicate transparently public.also showed important think humans impacted technology, putting human centre design \njust talking technology .follows, pause better define data scientists actually build, can specific tying potential harm different components data science pipeline.discuss progress made date way codifying ethics data science AI, conclude week offering codification problem area five major principles.five principles also serve backbone rest course. Welcome aboard!","code":""},{"path":"ch-foundations.html","id":"data-science-pipelines","chapter":"1 Foundations of Ethical AI","heading":"1.2 Data Science Pipelines","text":"previous section, covered detail consider ethical dimensions work data scientists. relied analogies professions doctors engineers.section, take break ethics get page exactly data scientists AI engineers build. model? product? business process? ’ll try come description fits common use cases . ’re practitioner already, recognize much follows. might refer different names another reason discussion align terminology use within course.ask question data scientists AI engineers build, likely get one two popular answers. Many technically minded faults say build models, regression model neural network. According people, output data scientist’s job trained machine learning model can make predictions real world. extreme, people without technical training might say build automated (partially automated) decision making systems. people think finished product operates world.argue course views incomplete. take view data scientists AI engineers build algorithms rather construct business processes used build algorithms, together call pipelines.broader view suitable purposes alllows holistic appreciation stages things can go wrong. take one thing away course work output data scientist pipeline generates model just model . sloppy pipeline without documentation bits pieces manual work one recalls can necessarily reproduce problematic work output, even resulting model incredible accuracy. mindset shift urgently needed just data scientists also managers public. Exclusive focus model accuracy invites complacency manufacturing process. Ask chef factory floor manager - clean organized working space underlies quality workLet’s take steps back. data science pipeline anyway? Let’s start classical use case machine learning, supervised learning. comes two main ‘flavours’, may met already.","code":""},{"path":"ch-foundations.html","id":"classification","chapter":"1 Foundations of Ethical AI","heading":"1.2.1 Classification","text":"[TODO: INSERT CAT PICTURE]’s cat. dog? brain pretty sure ’s cat even though don’t quite know . know see cat area within brain fires returns answer cat. known classification machine learning problem attaching label object based description features object. example binary classification two labels: cat dog.course, brain can much . picture giraffe, wouldn’t said “well neither cat dog… ’s closest cat ’ll go ”. (hopefully) immediately reported giraffe ridiculous call cat dog.brain acts like multi-class animal classifier, hundreds animals choose , just two. Even multi-class classifiers limitations - example may never seen first animal clear whether second chihuahua muffin. sort “sample” misapplication error common mode failure classifiers explore greater detail later course.[TODO: Add Bluefooted booby chihuahua/muffin images]Returning binary classifiers, might construct one? try write function describes set rules cat picture looks different dog picture. fact, early image classification techniques, known expert systems, just . long list rules developed trying exhaustively list differences dogs cats. ’s tedious work also humans learn tell dogs apart cats.child, know takes lot pointing trial error child learn animal looks. lot early childhood play fact training children classify objects: shapes, colours, animals . describing everyday objects, might sometimes revert explicit rules, example might say toddler dogs generally bigger cats. However, usually fine tune system put place looking large set labelled examples asking children extrapolate.[TODO: Insert Model schematic]Supervised learning follows logic. model two supporting functions: training function allows take input set examples \\(x\\) associated labels \\(y\\) use update internal state according optimization criterion. model also predict function, can provide label (may may correct) example given. can see predictive model really thought separate training data training algorithm. effect one object.Now let us look little bit abstractly. algorithm pre-specified list instructions takes input produces output. example addition takes input two numbers gives back sum.machine learning model complex, algorithm takes input training data set labelled examples outputs reality another algorithm fact software usually represented parameter \\(\\theta\\). parameter might single number, vector numbers, something quite bit complex. example linear logistic regression \\(\\theta\\) vector regression coefficients. fitted parameters \\(\\theta\\) can used input predictive model produces predicted label new example. can think predictive model just another algorithm two inputs: fitted parameters \\(\\theta\\) example like classify.Let’s revisit exactly mean label . example two possibilities “cat” “dog”, ’s binary classification. classification tool accept two labels, needs finite set determined advance. many real world variations problem labels nested hierarchical. might also convert numeric variable label convenience, example might predict whether value stock went , interested direction size change.often want predict probability possible label, rather returning likely label. known probabilistic, soft fuzzy classification, depending ask. little bit work, modern classifiers able produce score can interpreted probability, though underlying algorithm might actually designed . can sometimes result quite old-looking probabilities issue revisit discuss explainability detail.","code":""},{"path":"ch-foundations.html","id":"regression","chapter":"1 Foundations of Ethical AI","heading":"1.2.2 Regression","text":"settings, might want predict describe numeric variable, example yield crop price house. Usually referred regression problem, contrast classification problem met earlier. Many algorithms perform classification can also perform regression vice-versa, requiring minor modifications.","code":""},{"path":"ch-foundations.html","id":"unsupervised-learning","chapter":"1 Foundations of Ethical AI","heading":"1.2.3 Unsupervised Learning","text":"Finally, also types machine learning unsupervised, obvious target variable whose value want predict using number features. cases, might still want group examples together look similar spot ones look ordinary. full course dedicated supervised unsupervised learning - see examples module.","code":""},{"path":"ch-foundations.html","id":"modelling-as-part-of-a-pipeline","chapter":"1 Foundations of Ethical AI","heading":"1.2.4 Modelling as part of a Pipeline","text":"[TODO: Add pipeline image]know trained model just one part data scientist responsible . complete view offered Figure [TODO: REF]. standard data science pipeline starts data collected, either part existing process purposefully, say survey experiment. data pre-processed problem formulated needs addressed using data set including choice target variable. Ideally done collecting data first place, world messy place can available us.Following , features created (engineered) raw data several models trained resulting table features targets. performance measure used evaluate models identify best performing among considered. performance best model considered good enough deployed - one-use produce business insights, increasingly continuous use model made available service either pieces technology human users.production model monitored, least monitored, data scientists can stay abreast changes model performance issues might arise.breakdown data science workflow also guide exploration ethical risks step pipeline.","code":""},{"path":"ch-foundations.html","id":"data-collection","chapter":"1 Foundations of Ethical AI","heading":"1.2.4.1 Data Collection","text":"example, data collection stage aware historical biases represented data. biases likely bias model’s predictions addressed. example, using historical data see employees promoted rapidly organization influence future hires likely reproduce biases present promotion practices. Historical data can also biased terms record. example well known certain demographic groups United States, access health care difficult. means rates diagnosis certain diseases groups either smaller real prevalence disease arrive much later patient history. type selection mechanism can poison sorts downstream analysis.","code":""},{"path":"ch-foundations.html","id":"data-pre-processing","chapter":"1 Foundations of Ethical AI","heading":"1.2.4.2 Data Pre-processing","text":"data collected, typically needs extensive processing brought shape analysis. known data pre-processing recently falls general moniker data engineering. stage data science process often dismissed tedious mathematically uninteresting work yet stage bias can easily creep . Consider filling missing values - usually done using --shelf methods without much thought. usually results inappropriate techniques used, like filling value average variable across respondents. result overestimating weight women patient population, women tend weigh less men. Even challenging situations can arise value missing dependent value . example, survey trying estimate prevalence drug use people use drugs may less likely respond .","code":""},{"path":"ch-foundations.html","id":"formulating-your-research-question","chapter":"1 Foundations of Ethical AI","heading":"1.2.4.3 Formulating Your Research Question","text":"now come problem formulation stage, perhaps important . Einstein famously said “hour solve problem spend 55 minutes thinking problem 5 minutes thinking solutions”. clear, correct answerable question important two reasons. Firstly, asking wrong question can give wrong answer secondly step hard revisit later - model performance metric ever alert asked wrong question first place. Just like Douglas Adams said Hitchhiker’s Guide Galaxy, much harder build computer can tell right question ask build computer answers question .skill defining well-formed research questions particularly important problematic data science tools expect problems take specific shape, say classification regression. result tempting immediately look ways convert real world problem prediction task, hurry “real work” starts done. Another temptation assume job business person domain expert translation fault can’t answer vaguely defined question.\nfact forming good research questions can done well multi-disciplinary fashion. requires deep understanding domain application, business problem, modelling approach.Feature engineering carries similar challenges problem formulation many domain-specific assumptions can come little decisions need make create feature. unstructured semi-structured data set, feature engineering can manual time-consuming process also gives us chance understand problem domain. hand, modern techniques like end--end deep learning give us chance completely automate process using sophisticated computational approaches trial error. improves reproducibility speed pipeline, increase reliance bias-free data ’s opportunity correct self-reflect pipeline","code":""},{"path":"ch-foundations.html","id":"modelling-and-inference","chapter":"1 Foundations of Ethical AI","heading":"1.2.4.4 Modelling and Inference","text":"set predictive features choice target variable place, usually rely standard machine learning libraries like scikit-learn Python go types models, say random forest classifier, xgboost classifier logistic regression. fit data, assess performance select best performing one. optimization algorithm used fit classifier subsequent selection best performing one rely choice performance metric. metric important, defining relative severity different types errors. example, likely regard misclassifying patient cancer healthy severe error way around. However, false alarm also real costs - obvious emotional reasons also require follow-tests confirm diagnosis, might necessary initial classification correct. Choosing right performance metric half battle model selection huge number checks balances need kept avoid overfitting .","code":""},{"path":"ch-foundations.html","id":"deployment","chapter":"1 Foundations of Ethical AI","heading":"1.2.4.5 Deployment","text":"now completed task, model fitted say 93% sample accuracy. job done, right? Wrong.starers, model documented appropriate guard rails ensure used right way. Think back example using cat-dog classifier giraffe. serious example might smartphone app predicts risk heart failure next four weeks given number tests readings. need make sure app indeed deployed right data interpreted users right way.must also think access issues. just built great solution real world problem, can help make available users? want heart failure app used everyone just just folks expensive phones. might think job, can add value conversation may think. ways make algorithm computationally efficient, can run older generation phones? Perhaps drop accuracy switching faster algorithm worth , return solution available many people lives saved total.","code":""},{"path":"ch-foundations.html","id":"monitoring","chapter":"1 Foundations of Ethical AI","heading":"1.2.4.6 Monitoring","text":"one steps river twice said Heraclitus, sometimes abbreviated “everything changes”. model deployed, want make sure keep tracking performance - example speed, well number dimensions explore course. wouls like detect changes occur, example tested algorithm group older patients might want make sure performance applies population actual users, might younger. Even populations solution put production, sometimes world changes. COVID-19 pandemic really challenged many machine learning models built data collected prior beginning. Patterns human behaviour interaction changed many models retrained. effect known data set shift. One solution monitor model trigger reviews whenever indication something going wrong.unfortunately easy find real world examples risks going wrong. recent landmark publication highly esteemed journal Science, authors demonstrated algorithm used manage population health issues used health cost proxy health need. , understand much care someone suffering certain disease requires looked much money insurer spends per year. proxy ingenious idea, get around difficult data collection problem study used anonymised insurance claim data often available millions patients. However, study omitted fact groups people access high quality medical insurance. people therefore less care level need model trained data variable unfortunately perpetuate historical bias.","code":""},{"path":"ch-foundations.html","id":"notes-on-the-term-bias","chapter":"1 Foundations of Ethical AI","heading":"1.2.5 Notes on the term “bias”","text":"worth commenting use word bias course. used quite heavily ethical meaning, discrimination certain individuals groups, also number different technical meanings statistics data science.useful graphic get us think structured way presented paper Mitchell et al [TODO: add citation] presented also .[TODO: Add Mitchell graphic]view world free discrimination prejudice, however differs world , , due societal bias injustices taken place past. Even perfect capture human activity right now inherit bias. Unfortunately situation even worse . observe world imperfectly samples small even non-representative, introduces additional source bias statistical nature. graphic [TODO: ref Fig] useful reminder tease apart two sources bias require different mitigation strategy","code":""},{"path":"ch-foundations.html","id":"conclusion-1","chapter":"1 Foundations of Ethical AI","heading":"1.2.6 Conclusion","text":"section, defined mean data science work. highlighted important pay much emphasis pipeline generates predictive model predictive model . broke typical data science pipeline multiple stages explained stage poses ethical risks, showcasing examples along way.return discussion foundations order understand progress already made establishing best practices regulatory frameworks.","code":""},{"path":"ch-foundations.html","id":"moral-frameworks","chapter":"1 Foundations of Ethical AI","heading":"1.3 Moral Frameworks","text":"Section 1.1, explained need consider ethical matters data science professionals. next reviewed typical data science pipeline looks like gave examples risks stage pipeline can pose.now return discussion moral frameworks. objective today demystify term “ethical”, least terms ’s used course.","code":""},{"path":"ch-foundations.html","id":"how-do-we-determine-ethical-behaviour","chapter":"1 Foundations of Ethical AI","heading":"1.3.1 How do we determine ethical behaviour?","text":"Let’s first start reviewing shape moral opinions attitudes individuals. Morality sometimes result thoughtful rational exercise, many situations almost instinctive response. takes effort recognize precisely origins moral attitudes don’t always ability directly introspect .Clearly, society live influences think right wrong. said, societies can often pluralistic, divided . every division opinion large social group can probably find fair amount shared moral attitudes well, many people often simply stopped noticing paying attention since contented opinions.addition norms habits, philosophical viewpoints can influence moral attitudes big topics crime punishment, tradition versus progress, many others. community’s special history relationship surrounding society also important source moral views, along self-identity broader cultural influences. Another clear source moral attitudes course religion.Finally, professional lives can also play big role moral attitudes. can especially true case mission-driven professions like doctors, nurses teachers case strong corporate identities like ones surrounding lifelong careers single corporation recently certain technology companies.makes plurality sources interesting , often, can actually come conflict. Something ’re asked work might example contrary personal morality religious beliefs. might therefore seem like really hard problem hands: ethical data scientist first need agree definition means ethical person? Surely take us years study least. see shortly, ’s exactly required.","code":""},{"path":"ch-foundations.html","id":"medical-codes-of-conduct","chapter":"1 Foundations of Ethical AI","heading":"1.3.2 Medical Codes of Conduct","text":"Let us consider example doctors; professional group abides strict code conduct, relying four relatively simple principles:non-maleficence,beneficence,equity,autonomyNon-maleficence, idea doctor “harm” already encountered. Beneficence side coin, commitment intervene optimize health welfare patient. principle equity reminds us patients access equal care, regardless race ,gender attribute. Finally patient autonomy, includes privacy medical confidentiality asserts patient one decides whether want receive treatment doctor must support decision, even disagree.’s couple things observe . First, just four fairly generic simple state principles obviously enough tell doctor right thing given specific circumstance. done case--case basis ethics committees , particularly thorny cases, debated bioethics journals. However, principles offer robust framework new situation must analysed. Second, none principles mention social religious considerations. allow flexibility defining good, infinite amount wiggle-room. Looking specifically autonomy principle, precluded authoritarian state running experiments citizens without consent. emphasises professional codes conduct need complete philosophical treaties, written first principles nature good evil. Professional codes conduct instead contract trust professional society live within.doctor responsible good good obvious answer patient american medical association’s code medical ethics answers question us highlighted passage . Physicians says, must recognize responsibility patients first foremost, well society, health professionals, . hierarchy stakeholders patient coming first, society large second, doctors third self last.consider concrete example, medical doctor obligated offer antibiotics patient needs . doctor also needs also keep mind -prescription antibiotics , time, lead resistance drugs, harms broader public health. borderline cases , absent consideration resistance public health, doctor might prescribed antibiotics patient didn’t. moral dilemmas can tricky solve important first step recognize thinking expansively might affected work. rarely just user product service; commonly community, family, society large indirectly affected use AI-based service.","code":""},{"path":"ch-foundations.html","id":"codes-of-conduct-in-other-professions","chapter":"1 Foundations of Ethical AI","heading":"1.3.3 Codes of Conduct in Other Professions","text":"focused earlier Hippocratic oath broader professional codes conduct can enforced (can incur kind penalty respected) fairly recent development. pivotal moment development Nuremberg trials, prosecuted cruel, unthinkable human experiments run Nazi regime unfortunately also occurred authoritarian regimes. trial triggered need formulate explicit code medical conduct doctors can swear feel loyal . can act counterbalance loyalty employer government. Although Nuremberg trials absolutely extreme example, principle professionals owe allegiance loyalty profession loyalty employer, government, social group, religion absolutely foundational.Codes conduct therefore act fail-safe. chartered accountant obliged first one report fraud, even means reporting employer. medical doctor must respect patient autonomy, even desperate circumstances patient’s perspective. chartered statistician misrepresent data, even CEO start-work asks . Codes conduct nowhere near enforceable law ’re broader ’re agile, useful means rapidly evolving technologies self-regulate.another example: Royal Statistical Society’s code conduct specifically asks Fellows Society seek counter false misleading statements detrimental statistical science,profession, society. age fake news misinformation, oblige fellow RSS respond say Twitter thread misrepresents data pandemic? example employer strict policy something like ; entering public debates social media? need answer questions now, just need recognize important get asked.picture landing looks follows. Different professions codes conduct: statisticians, doctors, accountants, . folks daily work also loyalties companies, example technology pharmaceutical company, mission. result creative healthy tension corporate objectives, including limited profit making ones, professional ethics. tension helps companies organize healthy ethical practices. time, professionals personal identity, influenced societal norms set fairly universal moral values right privacy non-discrimination. Within specific individual exists similar amount creative healthy tension code conduct acting fail-safe specific beliefs given professional, may conflict occasionally welfare user.general medical council UK specifically describes ’re physician asked conduct procedure goes personal beliefs, morality religion. physician circumstances must explain patients conscientious objection particular procedure, must tell patient right see another doctor, make sure enough information exercise right. providing information may imply express disapproval patient’s lifestyle choices beliefs. gives space physician hold individual beliefs time making sure patient harmed misinformed result. emphasizes need seek codes conduct contracts trust can co-exist sources moral attitudes, rather absolutist statements truth.","code":""},{"path":"ch-foundations.html","id":"conclusion-2","chapter":"1 Foundations of Ethical AI","heading":"1.3.4 Conclusion","text":"Section 1.1 understood course , section instead covered . course, ethical AI whole, attempt exhaustively establish right. question touching upon philosophy, religion, politics, social sciences history; none taught course.clarified codes conduct obligations arise expect trust fellow citizens. also emphasized, , many modern codes conduct pieces regulation came humanitarian disasters. ambition hope AI data science self-regulate effective manner happens. Finally, used examples medical profession illustrate professional codes conduct can act fail-safes individual, corporate government misconduct.Throughout course, come question principles . simple set concepts create scaffold can analyse ethical implications work. Finally reached point can list set principles following section.","code":""},{"path":"ch-foundations.html","id":"five-principles-of-ethical-ai","chapter":"1 Foundations of Ethical AI","heading":"1.4 Five Principles of Ethical AI","text":"","code":""},{"path":"ch-foundations.html","id":"recap","chapter":"1 Foundations of Ethical AI","heading":"1.4.1 Recap","text":"first section course intense. ’ve covered lot ground.saw important us think ethical implications work, complex work data scientist really , stage work stream carries different ethical risks. also saw professional codes conduct act contract trust profession public. codes conduct can reduce vast complexity moral reasoning relatively simple general principles, guide us consider project dilemma individually. Equipped context, can now finally discuss principles ethical AI form structure rest course.","code":""},{"path":"ch-foundations.html","id":"medical-ethics-revisited","chapter":"1 Foundations of Ethical AI","heading":"1.4.2 Medical Ethics Revisited","text":"saw earlier medical ethics reduces complex space ethical medical care just four principles: non-maleficence, beneficence, equity autonomy.philosophical perspective privacy can seen special case autonomy; data many ways part therefore remain control. might therefore ask , four principles perhaps relevant even sufficient data science?points us important question study ethics, novelty. tempting assume revolutionary new technology like AI possibly fit ethical frameworks designed hundreds years ago. However, obvious problems posed AI fundamentally different ethical issues medicine, despite superficial differences.Take example autonomy. Various countries take different attitudes relative importance patient autonomy versus public health. explains issue compulsory vaccination heated point debate. exact way, different countries took different position relative importance privacy public health. early stages COVID pandemic, nations prepared disclose citizen location data order establish close contact notification systems, whereas nations type solution considered invasive; thought thought non-starter public acceptance perspective never even tried privacy grounds.Similarly, may questioned whether patient can really give informed consent complex medical treatment lack necessary background understand fully. reason, questioned whether loan applicants understand implications financial health apply loan consent credit history checked automatically via algorithm.AI medical interventions seem pose similar ethical issues terms autonomy, privacy consent examples.","code":""},{"path":"ch-foundations.html","id":"ethical-prinicples-for-data-science-and-ai","chapter":"1 Foundations of Ethical AI","heading":"1.4.3 Ethical Prinicples for Data Science and AI","text":"One important philosophers technology [TODO: citation slides] took reasoning step argued recent influential paper AI poses single new ethical problem, explainability. , first time human history, decisions going made algorithms humans. end day, one can always ask doctor made certain decision led patient harm hence can judge actions justifiable. one decision instead made deep neural network?[TODO: add Floridi Cowls figure]Figure [TODO: add fig ref] paper question [TODO: ref] entitled unified framework five principles ai society illustrates idea. need , argues, obtain set principles ethical AI take traditional set four bio-ethical principles add fifth explainability. principle given case human decision making far obvious case algorithmic decision making.also note medical ethics just one precursor data science ethics, albeit important one. history AI origins computer science data can already reveal number additional fields ethical study. begins computer ethics, moving data ethics ethics algorithms learn, can pose different challenges bias unpredictability. Yet another field ethics robots automation ethics, concerned moral hazard delegating decision making machines.final relative data science ethics mention slightly futuristic ethics artificial general intelligence. take leap far future, argue even though current AI systems require explainability additional ethical principle, AI systems future almost certainly need .One interesting example question whether AI systems might one day become capable suffering, least become convincing enough human-like behaviour unable tell really suffering . might okay cat take ride roomba (small household robot designed clean floors) okay kick robot, swear fails clean part room? type abuse harmed? Even accept roomba simple machine certainly ability suffer, might still risk developing toxic psychological habits regularly abuse human-like robots. , perhaps, another family genuinely new ethical questions philosophically interesting might also become increasingly relevant future, won’t discussing much course.","code":""},{"path":"ch-foundations.html","id":"artificial-general-intelligence","chapter":"1 Foundations of Ethical AI","heading":"1.4.4 Artificial General Intelligence","text":"Another ethical concern AI us eventually losing control . idea AI suddenly wakes decides terminate humanity old idea robots strong theme science fiction popular science writers. concern really apply simple data science pipelines current forms AI. refers instead known artificial general intelligence, term reserved systems able solve arbitrary cognitive problems opposed narrow AI, might able superhuman performance say chess go know asked cook dinner. Whether artificial general intelligence achievable open question. Prominent thinkers AI safety [TODO: REF?] believe matter low probability creating AGI damage control super intelligent computer cause high overall problem still studied earnest now.Science fiction describe future accurately useful. forms thought experiment take current trends logical extremes reveals ethical problems already exist. taking logical extremes issues plainer see.previous discussion AGI highlights relevant concerns humans can retain control autonomous decision-making systems. links back explainability. human ability correct action AI system, need able understand system . concern extends beyond just explainability, example consider self-driving car. like human passenger able rapidly take back control vehicle, however explainable artificial intelligence might .Another concern use AI optimize various production systems. cases must careful make sure optimizing right thing. ensure system create aligned true objectives values, simplified approximation . task known value alignment much easier said done. chance go quite deeply later course.Even put aside possibility evil robots, current AI technology can still present real present danger humanity. Autonomous weapons clear cut example threat technology companies promised pursue research direction. future life institute founded monitor mitigate existential risks gathered signatures thousands AI researchers prominent stakeholders declare commitment staying away dangerous space.","code":""},{"path":"ch-foundations.html","id":"ethical-deadends","chapter":"1 Foundations of Ethical AI","heading":"1.4.5 Ethical Deadends","text":"Moratoria decision pursue research space. Moratoria issued companies governments use case subtler risk profiles, facial recognition [TODO: REF]. outcome banning research area difficult predict, can seen decades-long efforts nuclear disarmament. Bad actors continue research spaces gain ground, matter regulations say. History tells us even democracies, possession extremely powerful tools dangerous weapons, might still make bad decisions. don’t time extend discussion course, important know professional codes conduct sometimes specific red lines certain use cases like autonomous weapons may well end falling beyond .","code":""},{"path":"ch-foundations.html","id":"five-principles-of-ethical-data-science","chapter":"1 Foundations of Ethical AI","heading":"1.4.6 Five Principles of Ethical Data Science","text":"finally position state preferred five principles ethical data science:Privacy AutonomyFairnessValue alignment controlExplainabilitySafety, security accountabilityPrivacy, autonomy fairness match respective bio-ethical principles. Value alignment control , technical, interpretation beneficence. principle explainability follows Floridi Cowls. final principle safety, security accountability inspired bio-ethical principle non-maleficence, rephrased draw focus need proper data governance liability structures.five principles structure technical content course. remainder part 1 course use one week explore principles. Parts 2 3 ethics module deep-dive topics greater detail.","code":""},{"path":"ch-foundations.html","id":"conclusion-3","chapter":"1 Foundations of Ethical AI","heading":"1.4.7 Conclusion","text":"final section, seen AI poses somewhat new versions challenges present areas medical ethics, data ethics, technology ethics. also seen altogether new challenges, like explainability perhaps also aspects within value alignment control.Concerns bout future technologies (artificial general intelligence) already exist (autonomous weapons) allowed us structure technical content coherent units. use factorization data science ethics five principles closely aligns one leading figures technology ethics.","code":""},{"path":"ch-privacy-and-autonomy.html","id":"ch-privacy-and-autonomy","chapter":"2 Privacy and Autonomy","heading":"2 Privacy and Autonomy","text":"Cross-references make easier readers find link elements book.","code":""},{"path":"ch-privacy-and-autonomy.html","id":"captioned-figures-and-tables","chapter":"2 Privacy and Autonomy","heading":"2.1 Captioned figures and tables","text":"Figures tables captions can also cross-referenced elsewhere book using \\@ref(fig:chunk-label) \\@ref(tab:chunk-label), respectively.See Figure 2.1.\nFigure 2.1: nice figure!\nDon’t miss Table 2.1.Table 2.1: nice table!","code":"\npar(mar = c(4, 4, .1, .1))\nplot(pressure, type = 'b', pch = 19)\nknitr::kable(\n  head(pressure, 10), caption = 'Here is a nice table!',\n  booktabs = TRUE\n)"},{"path":"ch-fairness.html","id":"ch-fairness","chapter":"3 Fairness","heading":"3 Fairness","text":"can add parts organize one book chapters together. Parts can inserted top .Rmd file, first-level chapter heading file.Add numbered part: # (PART) Act one {-} (followed # chapter)Add unnumbered part: # (PART\\*) Act one {-} (followed # chapter)Add appendix special kind un-numbered part: # (APPENDIX) stuff {-} (followed # chapter). Chapters appendix prepended letters instead numbers.","code":""},{"path":"ch-alignment-and-control.html","id":"ch-alignment-and-control","chapter":"4 Alignment and Control","heading":"4 Alignment and Control","text":"","code":""},{"path":"ch-alignment-and-control.html","id":"footnotes","chapter":"4 Alignment and Control","heading":"4.1 Footnotes","text":"Footnotes put inside square brackets caret ^[]. Like one 1.","code":""},{"path":"ch-alignment-and-control.html","id":"citations","chapter":"4 Alignment and Control","heading":"4.2 Citations","text":"Reference items bibliography file(s) using @key.example, using bookdown package2 (check last code chunk index.Rmd see citation key added) sample book, built top R Markdown knitr3 (citation added manually external file book.bib).\nNote .bib files need listed index.Rmd YAML bibliography key.bs4_book theme makes footnotes appear inline click . example book, added csl: chicago-fullnote-bibliography.csl index.Rmd YAML, include .csl file. download new style, recommend: https://www.zotero.org/styles/RStudio Visual Markdown Editor can also make easier insert citations: https://rstudio.github.io/visual-markdown-editing/#/citations","code":""},{"path":"ch-explainability.html","id":"ch-explainability","chapter":"5 Explainability and Interpretability","heading":"5 Explainability and Interpretability","text":"","code":""},{"path":"ch-explainability.html","id":"equations","chapter":"5 Explainability and Interpretability","heading":"5.1 Equations","text":"equation.\\[\\begin{equation}\n  f\\left(k\\right) = \\binom{n}{k} p^k\\left(1-p\\right)^{n-k}\n  \\tag{5.1}\n\\end{equation}\\]may refer using \\@ref(eq:binom), like see Equation (5.1).","code":""},{"path":"ch-explainability.html","id":"theorems-and-proofs","chapter":"5 Explainability and Interpretability","heading":"5.2 Theorems and proofs","text":"Theorem 5.1  right triangle, \\(c\\) denotes length hypotenuse\n\\(\\) \\(b\\) denote lengths two sides, \n\\[^2 + b^2 = c^2\\]Labeled theorems can referenced text using \\@ref(thm:tri), example, check smart theorem 5.1.Read https://bookdown.org/yihui/bookdown/markdown-extensions--bookdown.html.","code":""},{"path":"ch-explainability.html","id":"callout-blocks","chapter":"5 Explainability and Interpretability","heading":"5.3 Callout blocks","text":"bs4_book theme also includes special callout blocks, like .rmdnote.can use markdown inside block.user define appearance blocks LaTeX output.may also use: .rmdcaution, .rmdimportant, .rmdtip, .rmdwarning block name.R Markdown Cookbook provides help use custom blocks design callouts: https://bookdown.org/yihui/rmarkdown-cookbook/custom-blocks.html","code":"\nhead(beaver1, n = 5)\n#>   day time  temp activ\n#> 1 346  840 36.33     0\n#> 2 346  850 36.34     0\n#> 3 346  900 36.35     0\n#> 4 346  910 36.42     0\n#> 5 346  920 36.55     0"},{"path":"ch-safety.html","id":"ch-safety","chapter":"6 Safety, Security and Accountability","heading":"6 Safety, Security and Accountability","text":"","code":""},{"path":"ch-safety.html","id":"publishing","chapter":"6 Safety, Security and Accountability","heading":"6.1 Publishing","text":"HTML books can published online, see: https://bookdown.org/yihui/bookdown/publishing.html","code":""},{"path":"ch-safety.html","id":"pages","chapter":"6 Safety, Security and Accountability","heading":"6.2 404 pages","text":"default, users directed 404 page try access webpage found. ’d like customize 404 page instead using default, may add either _404.Rmd _404.md file project root use code /Markdown syntax.","code":""},{"path":"ch-safety.html","id":"metadata-for-sharing","chapter":"6 Safety, Security and Accountability","heading":"6.3 Metadata for sharing","text":"Bookdown HTML books provide HTML metadata social sharing platforms like Twitter, Facebook, LinkedIn, using information provide index.Rmd YAML. setup, set url book path cover-image file. book’s title description also used.bs4_book provides enhanced metadata social sharing, chapter shared unique description, auto-generated based content.Specify book’s source repository GitHub repo _output.yml file, allows users view chapter’s source file suggest edit. Read features output format :https://pkgs.rstudio.com/bookdown/reference/bs4_book.htmlOr use:","code":"\n?bookdown::bs4_book"},{"path":"license.html","id":"license","chapter":"License","heading":"License","text":"work licensed Creative Commons Attribution-ShareAlike 4.0 International License.human-readable summary (substitute ) license.\nPlease see https://creativecommons.org/licenses/-sa/4.0/legalcode full legal text.free :Share—copy redistribute material medium \nformatShare—copy redistribute material medium \nformatRemix—remix, transform, build upon material \npurpose, even commercially.Remix—remix, transform, build upon material \npurpose, even commercially.licensor revoke freedoms long follow \nlicense terms.following terms:Attribution—must give appropriate credit, provide link\nlicense, indicate changes made. may \nreasonable manner, way suggests licensor\nendorses use.Attribution—must give appropriate credit, provide link\nlicense, indicate changes made. may \nreasonable manner, way suggests licensor\nendorses use.ShareAlike—remix, transform, build upon material, must distribute contributions license original.ShareAlike—remix, transform, build upon material, must distribute contributions license original.additional restrictions—may apply legal terms \ntechnological measures legally restrict others \nanything license permits.additional restrictions—may apply legal terms \ntechnological measures legally restrict others \nanything license permits.Notices:comply license elements \nmaterial public domain use permitted \napplicable exception limitation.warranties given. license may give \npermissions necessary intended use. example, rights\npublicity, privacy, moral rights may limit use \nmaterial.","code":""},{"path":"build-information.html","id":"build-information","chapter":"Build Information","heading":"Build Information","text":"book written bookdown inside RStudio. website ethics-1.zakvarty.com hosted Netlify. complete source available GitHub.course logo designed Zak Varty.version book built :Along packages:","code":"#>  setting  value\n#>  version  R version 4.2.0 (2022-04-22)\n#>  os       macOS Big Sur/Monterey 10.16\n#>  system   x86_64, darwin17.0\n#>  ui       X11\n#>  language (EN)\n#>  collate  en_GB.UTF-8\n#>  ctype    en_GB.UTF-8\n#>  tz       Europe/London\n#>  date     2022-10-05\n#>  pandoc   2.18 @ /Applications/RStudio.app/Contents/MacOS/quarto/bin/tools/ (via rmarkdown)"},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
