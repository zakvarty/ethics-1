<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Course Overview | MLDS Ethics - Part 1</title>
<meta name="author" content="Zak Varty">
<meta name="description" content="This section is only relevant to students taking the MLDS course in the academic year 2022-23.  0.1 Welcome! Data-driven decision making is now pervasive and impacts us all. Your data is used by...">
<meta name="generator" content="bookdown 0.26 with bs4_book()">
<meta property="og:title" content="Course Overview | MLDS Ethics - Part 1">
<meta property="og:type" content="book">
<meta property="og:url" content="https://ethics-1.zakvarty.com/course-overview.html">
<meta property="og:image" content="https://ethics-1.zakvarty.com/assets/ethics-1-logo.jpg">
<meta property="og:description" content="This section is only relevant to students taking the MLDS course in the academic year 2022-23.  0.1 Welcome! Data-driven decision making is now pervasive and impacts us all. Your data is used by...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Course Overview | MLDS Ethics - Part 1">
<meta name="twitter:description" content="This section is only relevant to students taking the MLDS course in the academic year 2022-23.  0.1 Welcome! Data-driven decision making is now pervasive and impacts us all. Your data is used by...">
<meta name="twitter:image" content="https://ethics-1.zakvarty.com/assets/ethics-1-logo.jpg">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.1/transition.js"></script><script src="libs/bs3compat-0.3.1/tabs.js"></script><script src="libs/bs3compat-0.3.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="assets/style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">MLDS Ethics - Part 1</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Welcome!</a></li>
<li><a class="active" href="course-overview.html">Course Overview</a></li>
<li><a class="" href="ch-foundations.html"><span class="header-section-number">1</span> Foundations of Ethical AI</a></li>
<li><a class="" href="ch-privacy-and-autonomy.html"><span class="header-section-number">2</span> Privacy and Autonomy</a></li>
<li><a class="" href="ch-fairness.html"><span class="header-section-number">3</span> Fairness</a></li>
<li><a class="" href="ch-alignment-and-control.html"><span class="header-section-number">4</span> Alignment and Control</a></li>
<li><a class="" href="ch-explainability.html"><span class="header-section-number">5</span> Explainability and Interpretability</a></li>
<li><a class="" href="ch-safety.html"><span class="header-section-number">6</span> Safety, Security and Accountability</a></li>
<li><a class="" href="license.html">License</a></li>
<li><a class="" href="build-information.html">Build Information</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/zakvarty/ethics-1">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="course-overview" class="section level1 unnumbered">
<h1>Course Overview<a class="anchor" aria-label="anchor" href="#course-overview"><i class="fas fa-link"></i></a>
</h1>
<p>This section is only relevant to students taking the MLDS course in the
academic year 2022-23.</p>
<div id="welcome-1" class="section level2" number="0.1">
<h2>
<span class="header-section-number">0.1</span> Welcome!<a class="anchor" aria-label="anchor" href="#welcome-1"><i class="fas fa-link"></i></a>
</h2>
<p>Data-driven decision making is now pervasive and impacts us all. Your
data is used by others to make decisions about who you are, how you will
behave, and what options should be made available to you. Predictive
models are used to decide anything from the promotion that is offered to
you by a retailer through to whether your loan application is granted by
a bank.</p>
<p>The ways in which these predictive models can fail mathematically form a
core part of the training for an aspiring statistician, data scientist
or machine learning practitioner. In contrast, the potential for ethical
failures in these same models is rarely covered in-depth during as part
of this initial training. As a result, these ethical modes of failure
are often not considered until those predictive models have been put
into production and are actively causing harm.</p>
<p>To prevent this harm, the ethical impacts of using data to make
decisions must be made core to the curriculum of both statistics and
data science. This course aims to address that gap.</p>
<p>The course takes a practical and technical approach to identifying these
ethical issues. It has a strong mathematical focus and will not not
require the authoring of extended essays or moral treaties. Throughout
the course, you will discover actionable ways in which these topics may
be integrated into a data science workflow at a range of levels.</p>
</div>
<div id="module-description" class="section level2" number="0.2">
<h2>
<span class="header-section-number">0.2</span> Module Description<a class="anchor" aria-label="anchor" href="#module-description"><i class="fas fa-link"></i></a>
</h2>
<p>This module will investigate the ethical implications of the new
capabilities offered by Data Science and Artificial Intelligence.</p>
<p><strong>Part 1</strong> will begin by discussing the ethical use of data itself - the
raw materials of data science pipelines. It will then discuss sets of
principles that tech leaders and international bodies are adopting to
promote ethical use of data science and artificial intelligence
algorithms, including a discussion of real-world examples of failings
and adverse outcomes.</p>
<p><strong>Parts 2 and 3</strong> will then revisit the issues explored in Part 1 in
greater technical detail. These parts will introduce data science
methodologies that provide novel solutions to ethical problems of old
such as explainability, prejudice and bias.</p>
</div>
<div id="learning-objectives" class="section level2" number="0.3">
<h2>
<span class="header-section-number">0.3</span> Learning Objectives<a class="anchor" aria-label="anchor" href="#learning-objectives"><i class="fas fa-link"></i></a>
</h2>
<ol style="list-style-type: decimal">
<li><p>Recognise and accept responsibility for the societal impact of data
science and machine learning technologies;</p></li>
<li><p>Participate in the broader debate about the issues surrounding the
use of data science and machine learning for prediction, decision
making and knowledge generation tasks;</p></li>
<li><p>Identify common ethical pitfalls of data science and ML algorithms
via a mental “check-list” and evaluate the degree to which a given
algorithm is likely to conform with ethical best practices.</p></li>
<li><p>Formally test for common ethical pitfalls of data science and ML
algorithms;</p></li>
<li><p>Implement mitigation measures against the ethical risks posed by the
use of data science and ML algorithms;</p></li>
<li><p>Construct well-founded and evidence-based arguments with which to
positively influence the actions of stakeholders and
decision-makers;</p></li>
<li><p>Take a systems perspective to holistically appraise data science
projects on their ethical and societal impacts.</p></li>
</ol>
</div>
<div id="live-sessions-and-office-hours" class="section level2" number="0.4">
<h2>
<span class="header-section-number">0.4</span> Live Sessions and Office Hours<a class="anchor" aria-label="anchor" href="#live-sessions-and-office-hours"><i class="fas fa-link"></i></a>
</h2>
<p>During the course we will have up to two hours of contact time per week:
a weekly office hour and a fortnightly live session. These sessions will
alternate between 9am and 4pm on Fridays each week.</p>
<p><strong>Live sessions</strong> will mainly consist of guided group discussions to
further explore the topics covered each week. These sessions will be
recorded so that you may review them later in the course or if you
cannot attend due to time zone issues. Each live session will also have
some time allocated for questions on course material. These questions
can either be asked live or via the EdStem discussion forum.</p>
<p><strong>Office hours</strong> are a more informal session dedicated entirely to
answering your questions and will not be recorded. These will by default
be a group session of up to 40 minutes. This allows you to benefit from
the questions asked by other students as well as your own. The final 20
minutes of each session will be reserved for 1-1 discussions. To arrange
such a meeting, please contact the course lecturer by email at least 1
hour before the office hour begins. If no 1-1 meetings are arranged then
this time may be used at the lecturer’s discretion to extend the group
discussion.</p>
</div>
<div id="assessment" class="section level2" number="0.5">
<h2>
<span class="header-section-number">0.5</span> Assessment<a class="anchor" aria-label="anchor" href="#assessment"><i class="fas fa-link"></i></a>
</h2>
<p>Ethics Part 1 accounts for 20% of your overall grade for this module.
Ethics Part 2 and Ethics Part 3 each account for 40% of your overall
grade.</p>
<p>For Ethics Part 1, there will be two assessed elements: weekly
peer-reviewed written summaries of your assigned reading and one
summative assessment.<br>
You will have the opportunity to submit up to 6 reading summaries. These
will be peer-marked with these marks moderated by the course lecturer
and/or graduate teaching assistants. Your mark will be calculated as the
average of your 5 highest scoring submissions. In particular, this means
that you can miss one submission without any consequence.</p>
<p><strong>Note:</strong> each reading summary requires you to write your own summary
and to provide feedback to other students.</p>
<p>The weekly deadline for your <strong>written submission is Wednesday at 23:59
(UK)</strong> and the weekly deadline for the peer-feedback is <strong>Thursday at
23:59 (UK)</strong>.</p>
<div class="inline-table"><table style="width:96%;" class="table table-sm">
<caption>Ethics 1 Assessment Components</caption>
<colgroup>
<col width="18%">
<col width="23%">
<col width="18%">
<col width="18%">
<col width="18%">
</colgroup>
<thead><tr class="header">
<th>Assessment
type</th>
<th>Description</th>
<th>% of
Ethics
Module</th>
<th>Release
Date</th>
<th>Due Date</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Reading
Summaries</td>
<td>Weekly
summary of
one
assigned
reading
and
provision
of
peer-feedback
for two
other
students.</td>
<td>5</td>
<td><strong>Weekly,
Friday
09:00
(UK)</strong></td>
<td><strong>Following
Thursday
23:59 (UK)
</strong></td>
</tr>
<tr class="even">
<td>coursework</td>
<td>Individual
short
report.
This will
involve a
mixture of
worksheet
style
questions
and a
guided
case-study
to assess
technical
understanding
of the
course
content
alongside
its
implementation
and
limitations
when used in
context.</td>
<td>15</td>
<td>
<p><strong>Friday
25 Nov
2022,
09:00
(UK)</strong></p>
<p>[Week 8]</p>
</td>
<td>
<p><strong>Monday
05 Dec
2022,
23:59
(UK)</strong></p>
<p>[Week 11]</p>
</td>
</tr>
</tbody>
</table></div>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="index.html">Welcome!</a></div>
<div class="next"><a href="ch-foundations.html"><span class="header-section-number">1</span> Foundations of Ethical AI</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#course-overview">Course Overview</a></li>
<li><a class="nav-link" href="#welcome-1"><span class="header-section-number">0.1</span> Welcome!</a></li>
<li><a class="nav-link" href="#module-description"><span class="header-section-number">0.2</span> Module Description</a></li>
<li><a class="nav-link" href="#learning-objectives"><span class="header-section-number">0.3</span> Learning Objectives</a></li>
<li><a class="nav-link" href="#live-sessions-and-office-hours"><span class="header-section-number">0.4</span> Live Sessions and Office Hours</a></li>
<li><a class="nav-link" href="#assessment"><span class="header-section-number">0.5</span> Assessment</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/zakvarty/ethics-1/blob/master/00-overview.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/zakvarty/ethics-1/edit/master/00-overview.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>MLDS Ethics - Part 1</strong>" was written by Zak Varty. It was last built on 2022-10-10.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
